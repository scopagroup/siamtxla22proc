\mini
{mini20}
{Recent Developments in Model Reduction and Low Rank Algorithms}
{Organizers: Zhichao Peng \& Min Wang}
{Numerical simulations of many real world scientific and engineering problems from chemically reacting flows to plasma physics involve a large number of degrees of freedom. This makes the outer-loop applications such as optimization, control, design, sensing and uncertainty quantification computationally expensive. Model reduction techniques and low rank algorithms, which explore and utilize the underlying low rank feature of the underlying problem, could dramatically accelerate these large-scale simulations. In this minisyposium, we would focus on the recent developments in model reduction and low rank algorithms such as machine learning based methods, structure preserving methods and least squares methods.}
{Location: CBB 120}

\begin{talks}
\item\talk
{A symplectic deep autoencoder for Hamiltonian systems}
{Wei Guo$^{1}$, Qi Tang$^{2}$, Joshua Burby$^{2}$}
{1: Texas Tech University, 2: Los Alamos National Labotary}
\item\talk
{Contrast-independent partially explicit time discretizations for multiscale problems}
{Wenyuan Li$^{1}$,Yalchin Efendiev$^{1}$, Wing Tat Leung$^{2}$}
{1: Texas A\&M University, 2: City University of Hong Kong}
\item\talk
{Achieving Stable Long-Term Predictions in Machine Learning Architectures with Parameterization}
{Daniel Serino$^{1}$, Qi Tang$^{1}$, Joshua Burby$^{1}$}
{1: Los Alamos National Labotary}
\item\talk
{Bayesian operator inference for data-driven reduced-order modeling}
{Shane~A.~McQuarrie$^{1}$, Mengwu~Guo$^{2}$, and Karen~Willcox$^{1}$}
{1: The University of Texas at Austin, 2: University of Twente}
\end{talks}
\room
